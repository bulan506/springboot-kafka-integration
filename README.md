


# ğŸ”„ InformaciÃ³n Compartida entre Servicios - GringottsBank ğŸ¦

## ğŸ“‹ DescripciÃ³n

Este proyecto tiene como objetivo demostrar el funcionamiento de la comparticiÃ³n de informaciÃ³n entre servicios utilizando **Apache Kafka** como sistema de mensajerÃ­a. EstÃ¡ basado en un patrÃ³n **Producer-Consumer** donde los microservicios intercambian eventos para mantener sincronizados los datos.

El sistema simula un entorno bancario llamado **GringottsBank** y se enfoca en la comunicaciÃ³n efectiva entre servicios para compartir eventos de manera asÃ­ncrona y escalable.

## ğŸ›  TecnologÃ­as utilizadas

- ğŸš€ **Spring Boot**: Framework para construir los microservicios REST.
- ğŸ³ **Docker**: Para contenerizar y orquestar servicios dependientes.
- ğŸ¯ **Apache Kafka**: Sistema de mensajerÃ­a para intercambio de eventos Producer-Consumer.
- ğŸƒ **MongoDB**: Base de datos NoSQL para persistencia de datos.
- ğŸ“Š **Grafana y Loki**: Para visualizaciÃ³n y monitoreo centralizado de logs.

## âš™ï¸ Requisitos previos

- ğŸ³ Docker y Docker Compose instalados en el sistema.
- â˜• Java JDK 17+ para correr los proyectos Spring Boot localmente.
- ğŸ˜ Kafka, Zookeeper y MongoDB serÃ¡n levantados vÃ­a Docker Compose.

## ğŸš€ InstalaciÃ³n y ejecuciÃ³n

1. Clonar el repositorio:
   ```bash
   git clone <https://github.com/bulan506/investigacionIngenieria.git>
   cd comunicationProcess

2. Levantar los servicios de Kafka, Zookeeper y MongoDB usando Docker Compose:

   ```bash
   docker-compose up -d
   ```

3. Ejecutar cada microservicio por separado en su entorno local (por ejemplo, desde tu IDE o usando comandos Gradle):

   * ğŸŸ¢ Producer Service (ClientDataService)
   * ğŸ”µ Consumer Service (ConsumerDataService)
- Para ver el grafana y loki, abre el navegador y ingresa a la siguiente URL:
   ```bash
   http://localhost:3000
   ```
4. Monitorear los logs y mÃ©tricas desde Grafana y Loki, configurados en el `docker-compose.yml`.

## ğŸ“‚ Estructura del proyecto

* ğŸŸ¢ **Producer Service (ClientDataService)**: Servicio encargado de publicar eventos en Kafka.
* ğŸ”µ **Consumer Service (ConsumerDataService)**: Servicio encargado de consumir eventos y actualizar datos en MongoDB.
* ğŸ³ **docker-compose.yml**: Archivo para levantar Kafka, Zookeeper, MongoDB, Grafana y Loki.
* ğŸ“„ DocumentaciÃ³n adicional con configuraciones especÃ­ficas para Spring Boot y visualizaciÃ³n.

## ğŸ¯ Uso

El sistema simula la emisiÃ³n y recepciÃ³n de eventos relacionados con clientes bancarios. El Producer emite eventos como **"ClientSaved"** o **"AddressUpdated"**, que el Consumer procesa para mantener actualizada la informaciÃ³n en su base de datos.

## âš ï¸ Consideraciones

* No se requieren configuraciones adicionales para correr el proyecto, solo tener Docker y Java configurados correctamente.
* Los servicios pueden correr en paralelo y comunicarse vÃ­a Kafka sin dependencias directas.




